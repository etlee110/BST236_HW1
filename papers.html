<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Latest Papers from arXiv!!!!</title>
    <link rel="stylesheet" href="styles/main.css">
</head>
<body>
    <header>
        <h1>READ THE LATEST PAPERS (Times are UTC)</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home HERE</a></li>
                <li><a href="pacman.html">Play Pac-Man HERE</a></li>
                <li><a href="papers.html">Latest Papers HERE</a></li>
            </ul>
        </nav>
    </header>
    <main>
        <section id="papers">
            <h2>Recent Papers HURRY</h2>
            <p>Search keyword: physics</p>
            <p>Last updated: 2025-04-01 01:26:33</p>
            <div id="paper-list">
                <!-- Papers will be dynamically inserted here -->

        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2503.22677v1" target="_blank">DSO: Aligning 3D Generators with Simulation Feedback for Physical   Soundness</a></h3>
            <p><strong>Authors:</strong> Ruining Li, Chuanxia Zheng, Christian Rupprecht, Andrea Vedaldi</p>
            <p>Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2503.22676v1" target="_blank">TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D   Gaussian Splatting</a></h3>
            <p><strong>Authors:</strong>  Boyang,  Yu, Yanlin Jin, Ashok Veeraraghavan, Akshat Dave, Guha Balakrishnan</p>
            <p>We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2503.15427v2" target="_blank">Direct comparison of stochastic driven nonlinear dynamical systems for   combinatorial optimization</a></h3>
            <p><strong>Authors:</strong> Junpeng Hou, Amin Barzegar, Helmut G. Katzgraber</p>
            <p>Combinatorial optimization problems are ubiquitous in industrial applications. However, finding optimal or close-to-optimal solutions can often be extremely hard. Because some of these problems can be mapped to the ground-state search of the Ising model, tremendous effort has been devoted to developing solvers for Ising-type problems over the past decades. Recent advances in controlling and manipulating both quantum and classical systems have enabled novel computing paradigms such as quantum simulators and coherent Ising machines to tackle hard optimization problems. Here, we examine and benchmark several physics-inspired optimization algorithms, including coherent Ising machines, gain-dissipative algorithms, simulated bifurcation machines, and Hopfield neural networks, which we collectively refer to as stochastic-driven nonlinear dynamical systems. Most importantly, we benchmark these algorithms against random Ising problems with planted solutions and compare them to simulated annealing as a baseline leveraging the same software stack for all solvers. We further study how different numerical integration techniques and graph connectivity affect performance. This work provides an overview of a diverse set of new optimization paradigms.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2407.11119v3" target="_blank">Entanglement scaling and charge fluctuations in a Fermi liquid of   composite fermions</a></h3>
            <p><strong>Authors:</strong> Cristian Voinea, Songyang Pu, Ajit C. Balram, Zlatko Papić</p>
            <p>The composite fermion Fermi liquid (CFL) state at $\nu=1/2$ filling of a Landau level is a paradigmatic non-Fermi liquid borne out purely by Coulomb interactions. But in what ways is this exotic state of matter different from a Fermi liquid? The CFL entanglement entropy was indeed found to exhibit a significant enhancement compared to free electrons [Shao et al., Phys. Rev. Lett. 114, 206402 (2015)], which was subsequently ruled out as a finite-size effect by the study of a lattice CFL analog [Mishmash and Motrunich, Phys. Rev. B 94, 081110 (2016)]. Moreover, the enhancement was not observed in a quasi-one-dimensional limit of the Coulomb ground state at $\nu=1/2$ [Geraedts et al., Science 352, 197 (2016)]. Here, we revisit the problem of entanglement scaling in the CFL state realized in a two-dimensional electron gas. Using Monte Carlo evaluation of the second R\'enyi entropy $S_2$ for the CFL variational wave function, we show that the entanglement enhancement is present not only at $\nu=1/2$ but also at $\nu=1/4$, as well as in bosonic CFL states at $\nu=1$ and $\nu=1/3$ fillings. In all cases, we find the scaling of $S_2$ with subsystem size to be enhanced compared to the non-interacting case, and insensitive to the choice of geometry and projection to the lowest Landau level. We also demonstrate that, for CFL states, the variance of the particle number in a subsystem obeys area-law scaling with a universal subleading corner contribution, in stark contrast with free fermions. Our results establish the enhanced entanglement scaling and suppressed charge fluctuations as fingerprints of non-Fermi-liquid correlations in CFL states.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2503.22666v1" target="_blank">Comparative Analysis of Technological Fitness and Coherence at different   geographical scales</a></h3>
            <p><strong>Authors:</strong> Matteo Straccamore, Matteo Bruno, Andrea Tacchella</p>
            <p>Debates over the trade-offs between specialization and diversification have long intrigued scholars and policymakers. Specialization can amplify an economy by concentrating on core strengths, while diversification reduces vulnerability by distributing investments across multiple sectors. In this paper, we use patent data and the framework of Economic Complexity to investigate how the degree of technological specialization and diversification affects economic development at different scales: metropolitan areas, regions and countries. We examine two Economic Complexity indicators. Technological Fitness assesses an economic player's ability to diversify and generate sophisticated technologies, while Technological Coherence quantifies the degree of specialization by measuring the similarity among technologies within an economic player's portfolio. Our results indicate that a high degree of Technological Coherence is associated with increased economic growth only at the metropolitan area level, while its impact turns negative at larger scales. In contrast, Technological Fitness shows a U-shaped relationship with a positive effect in metropolitan areas, a negative influence at the regional level, and again a positive effect at the national level. These findings underscore the complex interplay between technological specialization and diversification across geographical scales. Understanding these distinctions can inform policymakers and stakeholders in developing tailored strategies for technological advancement and economic growth.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2503.22661v1" target="_blank">Non-linear and non-empirical double hybrid density functional</a></h3>
            <p><strong>Authors:</strong> Danish Khan</p>
            <p>We develop a non-linear and non-empirical (nLanE) double hybrid density functional derived from an accurate interpolation of the adiabatic connection in density functional theory, incorporating the correct asymptotic expansions. By bridging the second-order perturbative weak correlation limit with the fully interacting limit from the semi-local SCAN functional, nLanE-SCAN is free of fitted parameters while providing improved energetic predictions compared to SCAN for moderately and strongly correlated systems alike. It delivers accurate predictions for atomic total energies and multiple reaction datasets from the GMTKN55 benchmark while significantly outperforming traditional linear hybrids and double hybrids for non-covalent interactions without requiring dispersion corrections. Due to the exact constraints at the weak correlation limit, nLanE-SCAN has reduced delocalization errors as evident through SIE4x4 and bond dissociations of H\(_2^+\) and He\(_2^+\). Its proper asymptotic behavior ensures stability in strongly correlated systems, improving H\(_2\) and N\(_2\) bond dissociation profiles compared to conventional functionals.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2503.22659v1" target="_blank">R-matrix valued Lax pair for elliptic Calogero-Inozemtsev system and   associative Yang-Baxter equations of ${\rm BC}_n$ type</a></h3>
            <p><strong>Authors:</strong> M. Matushko, A. Mostovskii, A. Zotov</p>
            <p>We consider the elliptic Calogero-Inozemtsev system of ${\rm BC}_n$ type with five arbitrary constants and propose $R$-matrix valued generalization for $2n\times 2n$ Takasaki's Lax pair. For this purpose we extend the Kirillov's ${\rm B}$-type associative Yang-Baxter equations to the similar relations depending on the spectral parameters and the Planck constants. General construction uses the elliptic Shibukawa-Ueno $R$-operator and the Komori-Hikami $K$-operators satisfying reflection equation. Then, using the Felder-Pasquier construction the answer for the Lax pair is also written in terms of the Baxter's 8-vertex $R$-matrix. As a by-product of the constructed Lax pair we also propose ${\rm BC}_n$ type generalization for the elliptic XYZ long-range spin chain, and we present arguments pointing to its integrability.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2503.22656v1" target="_blank">Differential equation quantum solvers: engineering measurements to   reduce cost</a></h3>
            <p><strong>Authors:</strong> Annie Paine, Casper Gyurik, Antonio Andrea Gentile</p>
            <p>Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2503.22654v1" target="_blank">On the effects of parameters on galaxy properties in CAMELS and the   predictability of $Ω_{\rm m}$</a></h3>
            <p><strong>Authors:</strong> Gabriella Contardo, Roberto Trotta, Serafina Di Gioia, David W. Hogg, Francisco Villaescusa-Navarro</p>
            <p>Recent analyses of cosmological hydrodynamic simulations from CAMELS have shown that machine learning models can predict the parameter describing the total matter content of the universe, $\Omega_{\rm m}$, from the features of a single galaxy. We investigate the statistical properties of two of these simulation suites, IllustrisTNG and ASTRID, confirming that $\Omega_{\rm m}$ induces a strong displacement on the distribution of galaxy features. We also observe that most other parameters have little to no effect on the distribution, except for the stellar-feedback parameter $A_{SN1}$, which introduces some near-degeneracies that can be broken with specific features. These two properties explain the predictability of $\Omega_{\rm m}$. We use Optimal Transport to further measure the effect of parameters on the distribution of galaxy properties, which is found to be consistent with physical expectations. However, we observe discrepancies between the two simulation suites, both in the effect of $\Omega_{\rm m}$ on the galaxy properties and in the distributions themselves at identical parameter values. Thus, although $\Omega_{\rm m}$'s signature can be easily detected within a given simulation suite using just a single galaxy, applying this result to real observational data may prove significantly more challenging.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2503.22652v1" target="_blank">Residual-based Chebyshev filtered subspace iteration for sparse   Hermitian eigenvalue problems tolerant to inexact matrix-vector products</a></h3>
            <p><strong>Authors:</strong> Nikhil Kodali, Kartick Ramakrishnan, Phani Motamarri</p>
            <p>Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.</p>
        </div>
        <hr>
        
<!-- END PAPERS -->
            </div>
        </section>
    </main>
</body>
</html>
