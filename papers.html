<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Latest Papers from arXiv!!!!</title>
    <link rel="stylesheet" href="styles/main.css">
</head>
<body>
    <header>
        <h1>READ THE LATEST PAPERS (Times are UTC)</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home HERE</a></li>
                <li><a href="pacman.html">Play Pac-Man HERE</a></li>
                <li><a href="papers.html">Latest Papers HERE</a></li>
            </ul>
        </nav>
    </header>
    <main>
        <section id="papers">
            <h2>Recent Papers HURRY</h2>
            <p>Search keyword: physics</p>
            <p>Last updated: 2025-02-20 01:12:48</p>
            <div id="paper-list">
                <!-- Papers will be dynamically inserted here -->

        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2502.13144v1" target="_blank">RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based   Reinforcement Learning</a></h3>
            <p><strong>Authors:</strong> Hao Gao, Shaoyu Chen, Bo Jiang, Bencheng Liao, Yiang Shi, Xiaoyang Guo, Yuechuan Pu, Haoran Yin, Xiangyu Li, Xinbang Zhang, Ying Zhang, Wenyu Liu, Qian Zhang, Xinggang Wang</p>
            <p>Existing end-to-end autonomous driving (AD) algorithms typically follow the Imitation Learning (IL) paradigm, which faces challenges such as causal confusion and the open-loop gap. In this work, we establish a 3DGS-based closed-loop Reinforcement Learning (RL) training paradigm. By leveraging 3DGS techniques, we construct a photorealistic digital replica of the real physical world, enabling the AD policy to extensively explore the state space and learn to handle out-of-distribution scenarios through large-scale trial and error. To enhance safety, we design specialized rewards that guide the policy to effectively respond to safety-critical events and understand real-world causal relationships. For better alignment with human driving behavior, IL is incorporated into RL training as a regularization term. We introduce a closed-loop evaluation benchmark consisting of diverse, previously unseen 3DGS environments. Compared to IL-based methods, RAD achieves stronger performance in most closed-loop metrics, especially 3x lower collision rate. Abundant closed-loop results are presented at https://hgao-cv.github.io/RAD.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2502.13142v1" target="_blank">Pre-training Auto-regressive Robotic Models with 4D Representations</a></h3>
            <p><strong>Authors:</strong> Dantong Niu, Yuvan Sharma, Haoru Xue, Giscard Biamby, Junyi Zhang, Ziteng Ji, Trevor Darrell, Roei Herzig</p>
            <p>Foundation models pre-trained on massive unlabeled datasets have revolutionized natural language and computer vision, exhibiting remarkable generalization capabilities, thus highlighting the importance of pre-training. Yet, efforts in robotics have struggled to achieve similar success, limited by either the need for costly robotic annotations or the lack of representations that effectively model the physical world. In this paper, we introduce ARM4R, an Auto-regressive Robotic Model that leverages low-level 4D Representations learned from human video data to yield a better pre-trained robotic model. Specifically, we focus on utilizing 3D point tracking representations from videos derived by lifting 2D representations into 3D space via monocular depth estimation across time. These 4D representations maintain a shared geometric structure between the points and robot state representations up to a linear transformation, enabling efficient transfer learning from human video data to low-level robotic control. Our experiments show that ARM4R can transfer efficiently from human video data to robotics and consistently improves performance on tasks across various robot environments and configurations.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2501.16206v2" target="_blank">Non-Gaussian density fluctuations in the Dean-Kawasaki equation</a></h3>
            <p><strong>Authors:</strong> Pierre Illien, Antoine Carof</p>
            <p>Computing analytically the $n$-point density correlations in systems of interacting particles is a long-standing problem of statistical physics, with a broad range of applications, from the interpretation of scattering experiments in simple liquids, to the understanding of their collective dynamics. For Brownian particles, i.e. with overdamped Langevin dynamics, the microscopic density obeys a stochastic evolution equation, known as the Dean-Kawasaki equation. In spite of the importance of this equation, its complexity makes it very difficult to analyze the statistics of the microscopic density beyond simple Gaussian approximations. In this work, resorting to a path-integral description of the stochastic dynamics and relying on the formalism of macroscopic fluctuation theory, we go beyond the usual linearization of the Dean-Kawasaki equation, and we compute perturbatively the three-point density correlation functions, in the limit of high-density and weak interactions between the particles. This exact result opens the way to using the Dean-Kawasaki beyond the simple Gaussian treatments, and could find applications to understand many fluctuation-related effects in soft and active matter systems.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2502.13130v1" target="_blank">Magma: A Foundation Model for Multimodal AI Agents</a></h3>
            <p><strong>Authors:</strong> Jianwei Yang, Reuben Tan, Qianhui Wu, Ruijie Zheng, Baolin Peng, Yongyuan Liang, Yu Gu, Mu Cai, Seonghyeon Ye, Joel Jang, Yuquan Deng, Lars Liden, Jianfeng Gao</p>
            <p>We present Magma, a foundation model that serves multimodal AI agentic tasks in both the digital and physical worlds. Magma is a significant extension of vision-language (VL) models in that it not only retains the VL understanding ability (verbal intelligence) of the latter, but is also equipped with the ability to plan and act in the visual-spatial world (spatial-temporal intelligence) and complete agentic tasks ranging from UI navigation to robot manipulation. To endow the agentic capabilities, Magma is pretrained on large amounts of heterogeneous datasets spanning from images, videos to robotics data, where the actionable visual objects (e.g., clickable buttons in GUI) in images are labeled by Set-of-Mark (SoM) for action grounding, and the object movements (e.g., the trace of human hands or robotic arms) in videos are labeled by Trace-of-Mark (ToM) for action planning. Extensive experiments show that SoM and ToM reach great synergy and facilitate the acquisition of spatial-temporal intelligence for our Magma model, which is fundamental to a wide range of tasks as shown in Fig.1. In particular, Magma creates new state-of-the-art results on UI navigation and robotic manipulation tasks, outperforming previous models that are specifically tailored to these tasks. On image and video-related multimodal tasks, Magma also compares favorably to popular large multimodal models that are trained on much larger datasets. We make our model and code public for reproducibility at https://microsoft.github.io/Magma.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2502.13124v1" target="_blank">NaturalReasoning: Reasoning in the Wild with 2.8M Challenging Questions</a></h3>
            <p><strong>Authors:</strong> Weizhe Yuan, Jane Yu, Song Jiang, Karthik Padthe, Yang Li, Dong Wang, Ilia Kulikov, Kyunghyun Cho, Yuandong Tian, Jason E Weston, Xian Li</p>
            <p>Scaling reasoning capabilities beyond traditional domains such as math and coding is hindered by the lack of diverse and high-quality questions. To overcome this limitation, we introduce a scalable approach for generating diverse and challenging reasoning questions, accompanied by reference answers. We present NaturalReasoning, a comprehensive dataset comprising 2.8 million questions that span multiple domains, including STEM fields (e.g., Physics, Computer Science), Economics, Social Sciences, and more. We demonstrate the utility of the questions in NaturalReasoning through knowledge distillation experiments which show that NaturalReasoning can effectively elicit and transfer reasoning capabilities from a strong teacher model. Furthermore, we demonstrate that NaturalReasoning is also effective for unsupervised self-training using external reward models or self-rewarding.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2501.16313v2" target="_blank">Transient Dynamics and Homogenization in Incoherent Collision Models</a></h3>
            <p><strong>Authors:</strong> Göktuğ Karpat, Barış Çakmak</p>
            <p>Collision models have attracted significant attention in recent years due to their versatility to simulate open quantum systems in different dynamical regimes. They have been used to study various interesting phenomena such as the dynamical emergence of non-Markovian memory effects and the spontaneous establishment of synchronization in open quantum systems. In such models, the repeated pairwise interactions between the system and the environment and also the possible coupling between different environmental units are typically modeled using the coherent partial-swap (PSWAP) operation as it is known to be a universal homogenizer. In this study, we investigate the dynamical behavior of incoherent collision models, where the interactions between different units are modeled by the incoherent controlled-swap (CSWAP) operation, which is also a universal homogenizer. Even though the asymptotic dynamics of the open system in case of both coherent and incoherent swap interactions appear to be identical, its transient dynamics turns out to be significantly different. Here we present a comparative analysis of the consequences of having coherent or incoherent couplings in collision models, namely, PSWAP or CSWAP interactions respectively, for the emergence of memory effects for a single qubit system and for the onset synchronization between a pair of qubits, both of which are strictly determined by the transient dynamics of the open system.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2211.16379v2" target="_blank">Elfs, trees and quantum walks</a></h3>
            <p><strong>Authors:</strong> Simon Apers, Stephen Piddock</p>
            <p>We study an elementary Markov process on graphs based on electric flow sampling (elfs). The elfs process repeatedly samples from an electric flow on a graph. While the sinks of the flow are fixed, the source is updated using the electric flow sample, and the process ends when it hits a sink vertex.   We argue that this process naturally connects to many key quantities of interest. E.g., we describe a random walk coupling which implies that the elfs process has the same arrival distribution as a random walk. We also analyze the electric hitting time, which is the expected time before the process hits a sink vertex. As our main technical contribution, we show that the electric hitting time on trees is logarithmic in the graph size and weights.   The initial motivation behind the elfs process is that quantum walks can sample from electric flows, and they can hence implement this process very naturally. This yields a quantum walk algorithm for sampling from the random walk arrival distribution, which has widespread applications. It complements the existing line of quantum walk search algorithms which only return an element from the sink, but yield no insight in the distribution of the returned element. By our bound on the electric hitting time on trees, the quantum walk algorithm on trees requires quadratically fewer steps than the random walk hitting time, up to polylog factors.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2502.09628v2" target="_blank">Characterizing nonlinear dynamics by contrastive cartography</a></h3>
            <p><strong>Authors:</strong> Nicolas Romeo, Chris Chi, Aaron R. Dinner, Elizabeth R. Jerison</p>
            <p>The qualitative study of dynamical systems using bifurcation theory is key to understanding systems from biological clocks and neurons to physical phase transitions. Data generated from such systems can feature complex transients, an unknown number of attractors, and stochasticity. Making an analogy to bifurcation analysis, which specifies that useful dynamical features are often invariant to coordinate transforms, we leverage contrastive learning to devise a generic tool to discover dynamical classes from stochastic trajectory data. By providing a model-free trajectory analysis tool, this method automatically recovers the dynamical phase diagram of known models and provides a "map" of dynamical behaviors for a large ensemble of dynamical systems. The method thus provides a way to characterize and compare dynamical trajectories without governing equations or prior knowledge of target behavior. This approach can be used as a standalone analysis tool, or as part of a broader data-driven analysis framework.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2412.02645v3" target="_blank">Gravitational waves from supercooled phase transitions in conformal   Majoron models of neutrino mass</a></h3>
            <p><strong>Authors:</strong> João Gonçalves, Danny Marfatia, António P. Morais, Roman Pasechnik</p>
            <p>We study supercooled first-order phase transitions above the QCD scale in a wide class of conformal Majoron-like U(1)' models that explain the totality of active neutrino oscillation data and produce a detectable stochastic gravitational wave background (SGWB) at LIGO, LISA and ET. We place constraints on the U(1)' breaking scale and gauge coupling using current LIGO-Virgo-Kagra data. We find that strong supercooling can be ruled out in large regions of parameter space if a SGWB is not detected by these experiments. A null signal at LIGO and ET will disfavor a type-I seesaw scale above $10^{14}$ GeV, while a positive signal is a signature of heavy right-handed neutrinos. On the other hand, LISA will be sensitive to seesaw scales as low as a TeV, and could detect a SGWB even if the right-handed neutrinos are decoupled.</p>
        </div>
        <hr>
        
        <div class="paper">
            <h3><a href="http://arxiv.org/pdf/2502.13102v1" target="_blank">Initial-state-driven spin correlations in high-energy nuclear collisions</a></h3>
            <p><strong>Authors:</strong> Giuliano Giacalone, Enrico Speranza</p>
            <p>In the study of spin-polarization phenomena in heavy-ion collisions, it is typically assumed that final-state particles are polarized through thermal vorticity and shear. In this sense, polarization is a final-state effect. Here, we propose a different mechanism. We postulate that the collision of spin-carrying nucleons generates an initial transverse spin density, inducing a net polarization of the QCD fireball along a random direction. If the net spin is conserved throughout the evolution of the fireball, the final-state particles should exhibit measurable polarization. Within a wounded nucleon picture, we estimate that initial-state fluctuations induce a net polarization of $\Lambda$ baryons which is around $1\%$ in central collisions and over $10\%$ in noncentral collisions, significantly exceeding the contributions from thermal vorticity and shear. We introduce a two-particle angular correlation observable designed to reveal initial net-spin fluctuations, and emphasize the main signatures to look for in experiments. We argue that the discovery of these phenomena would have profound implications for nuclear structure and our understanding of spin in relativistic hydrodynamics.</p>
        </div>
        <hr>
        
<!-- END PAPERS -->
            </div>
        </section>
    </main>
</body>
</html>
